{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOSrcDdIfz+/Rk3hmdWJVmB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pjivctpnfsN","executionInfo":{"status":"ok","timestamp":1718568550035,"user_tz":-180,"elapsed":72088,"user":{"displayName":"Роман Новиков","userId":"11314059983207211964"}},"outputId":"7db9db33-1804-45e9-96d0-65b2ef7fa377"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.33-py3-none-any.whl (780 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/780.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/780.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m778.2/780.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.6/780.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=0.2.5 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.33 ultralytics-thop-2.0.0\n"]}],"source":["pip install ultralytics\n"]},{"cell_type":"code","source":["import os\n","%cd /content/\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.mkdir(\"export\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4Xfhox2n7SI","executionInfo":{"status":"ok","timestamp":1718568579664,"user_tz":-180,"elapsed":26901,"user":{"displayName":"Роман Новиков","userId":"11314059983207211964"}},"outputId":"16978977-622a-4c2a-92d4-fc80662d1211"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/export\n","!unzip -qq \"/content/drive/MyDrive/Dataset 2.zip\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdbVuHv3oGYs","executionInfo":{"status":"ok","timestamp":1718568896365,"user_tz":-180,"elapsed":307015,"user":{"displayName":"Роман Новиков","userId":"11314059983207211964"}},"outputId":"c06d2582-f79f-4928-f039-174bb54dddee"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/export\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","model = YOLO('/content/drive/MyDrive/Res/yolov8n.pt')"],"metadata":{"id":"__hNZbPrqBj4","executionInfo":{"status":"ok","timestamp":1718568929845,"user_tz":-180,"elapsed":7056,"user":{"displayName":"Роман Новиков","userId":"11314059983207211964"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["results = model.train(\n","    data='/content/drive/MyDrive/datasetv8.yaml',\n","    imgsz=640,\n","    epochs=10,\n","    batch=4,\n","    name='/content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e',\n","    device='cuda'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_053tAPsNB6","executionInfo":{"status":"ok","timestamp":1718577511488,"user_tz":-180,"elapsed":8141984,"user":{"displayName":"Роман Новиков","userId":"11314059983207211964"}},"outputId":"c1d76b37-60e5-41a8-b624-7c0795dd4ae2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.33 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Res/yolov8n.pt, data=/content/drive/MyDrive/datasetv8.yaml, epochs=10, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=None, name=yolov8n_fistech_techniks_v8_50e2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    753457  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n","Model summary: 225 layers, 3012993 parameters, 3012977 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/export/Dataset 2/Train/labels.cache... 9257 images, 4093 backgrounds, 7 corrupt: 100%|██████████| 12928/12928 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/4246_jpg.rf.3af711a42195ff50f0ab50396309940e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/4246_jpg.rf.3af711a42195ff50f0ab50396309940e.jpgblack.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/4246_jpg.rf.3af711a42195ff50f0ab50396309940e.jpgnegative.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/4246_jpg.rf.3af711a42195ff50f0ab50396309940e.jpgsepia.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0094]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/Bulldozer-Wallpaper-1080p-270x150.jpg.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0067]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/Bulldozer-Wallpaper-High-Definition-270x150.jpg.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0133]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Train/images/tankers_0-943077802658081_png.rf.2766707b443f807f5b4ba47b9de73ef5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0471]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/export/Dataset 2/Val/labels.cache... 4220 images, 338 backgrounds, 34 corrupt: 100%|██████████| 4228/4228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-23_jpg.rf.3d1f306dc2ab081869ad34ebadab8fef.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-25_jpg.rf.89ccc5308dbaa361c1a348543e94a6df.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0656]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-55_jpg.rf.28d31f385589db33273f98fce2876007.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1734]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-69_jpg.rf.b386620770e50df2a06e38f9c93cd6d2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0875]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-70_jpg.rf.24c6dcd2feb292d18555195db459f842.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-73_jpg.rf.52dc90e46f3783472a813b34f3145ed0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1391      1.0078]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/-9_jpg.rf.78fccc059638753411b02b162875d943.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/M_M_images47_jpg.rf.050c684ec523e60d13b51c6c371607f2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0125]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_106_jpg.rf.fb55c1101686b9a8c14518b877873e18.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1404_jpg.rf.b8ca58b35b42757d3b54cefe6d27f544.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1441_jpg.rf.2ee57504e2471a3e01f3afd118d882fc.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1519_jpg.rf.db4b286bfa8e60a48741f6eeb3acdc96.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1615_jpg.rf.3b359c46309f62b74a8cbfbe230de9cb.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1651_jpg.rf.de3cbe5dbd4e2001c6fc64d7a3793e3b.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1687_jpg.rf.1a67013716bb08bd7bc993b2be4f1ed4.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_173_jpg.rf.338ae5bc7d0d590797288cf8f911d9b3.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1798_jpg.rf.14080d866dc42e9dae42edb7095d3986.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1896_jpg.rf.6a262e63290112fb2b164cf7d9a6398f.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_1939_jpg.rf.a227cec3d0679c002ea5b58da62230ea.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_199_jpg.rf.2a49bcea2c70106e1b373fbc4a88e443.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_2052_jpg.rf.415c7c0a493676c343b11fa88ca3ecc2.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_2619_jpg.rf.1c5cac9a790e2b03437631f08330a54a.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_2645_jpg.rf.927caa8001272b4d040f4f11de68234a.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_2716_jpg.rf.6ddfc2493d1ddf534a48fc642afe387e.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_2775_jpg.rf.e4fa54aa9c8b0d2ca61b03852f7d6bf5.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_2848_jpg.rf.bc18db42fa6fc80e23453eb806333c03.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_3027_jpg.rf.266f196c65a64dc0903394a7a2e0b008.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_3029_jpg.rf.22b896b00b89ad80e0d31676b5121dfa.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_437_jpg.rf.7eda00db48a0cc7db3ae783448489fb4.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_551_jpg.rf.d1744de602a63b13e0dde49f08663bbb.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_582_jpg.rf.5638743a430860c54baf5cedcba51f98.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_58_jpg.rf.90e054e79b94c51b1745e64f773e19d3.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/frame_76_jpg.rf.32a228b820d99b933acbb2408372435d.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/export/Dataset 2/Val/images/hyundai-15-18-20bt-9u_jpg.rf.be38d32ef6c523f35a20b07b88a80eec.jpg: ignoring corrupt image/label: could not convert string to float: 'undefined'\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/10      1.21G      1.155       3.27      1.501          1        640: 100%|██████████| 3231/3231 [11:21<00:00,  4.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  87%|████████▋ | 456/525 [02:07<00:36,  1.90it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:17<00:00,  3.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967       0.29      0.258      0.225      0.147\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/10       1.2G      1.147      1.959      1.496          1        640: 100%|██████████| 3231/3231 [11:12<00:00,  4.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:15<00:00,  3.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.372      0.228      0.219      0.135\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/10      1.21G      1.107      1.543      1.454          0        640: 100%|██████████| 3231/3231 [11:05<00:00,  4.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:13<00:00,  3.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.448      0.229       0.23      0.157\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/10      1.19G      1.057      1.369      1.418          1        640: 100%|██████████| 3231/3231 [11:01<00:00,  4.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:16<00:00,  3.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.409       0.26      0.278      0.186\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/10      1.19G     0.9798      1.191      1.353          1        640: 100%|██████████| 3231/3231 [10:52<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:10<00:00,  4.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.419      0.241       0.27      0.182\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/10      1.19G     0.9266      1.096      1.314          3        640: 100%|██████████| 3231/3231 [10:55<00:00,  4.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:16<00:00,  3.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.406       0.27      0.285      0.197\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/10      1.19G     0.8853     0.9976      1.282          0        640: 100%|██████████| 3231/3231 [10:56<00:00,  4.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:14<00:00,  3.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967       0.43      0.258      0.267       0.18\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/10      1.21G     0.8385     0.9198      1.239          2        640: 100%|██████████| 3231/3231 [10:54<00:00,  4.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:12<00:00,  3.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.391      0.262      0.272      0.193\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/10      1.19G     0.7855     0.8537      1.201          4        640: 100%|██████████| 3231/3231 [10:53<00:00,  4.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:16<00:00,  3.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.392      0.255      0.272      0.193\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/10      1.19G     0.7516     0.8317      1.168          1        640: 100%|██████████| 3231/3231 [11:16<00:00,  4.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:10<00:00,  4.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.427      0.295        0.3      0.214\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","10 epochs completed in 2.221 hours.\n","Optimizer stripped from /content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2/weights/last.pt, 6.3MB\n","Optimizer stripped from /content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2/weights/best.pt, 6.3MB\n","\n","Validating /content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2/weights/best.pt...\n","Ultralytics YOLOv8.2.33 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3007793 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 525/525 [02:06<00:00,  4.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       4194       6967      0.429      0.295        0.3      0.214\n"," Dump truck \\ Самосвал        809       1104      0.549      0.178      0.216       0.16\n","Excavator \\ Экскаватор       1292       1483      0.957       0.13      0.362      0.288\n","Motor grader \\ Автогрейдер        104        105      0.916      0.552      0.664      0.498\n","        Roller \\ Каток         97         97    0.00474     0.0515    0.00146    0.00117\n","CMU (Manipulator Crane) \\ КМУ (Кран-манипулятор)        272        272     0.0323     0.0404     0.0603     0.0207\n","Trailer (Truck, Gazelle) \\ Прицеп (Фура, газель)        682        768      0.148       0.12     0.0585     0.0416\n","Forklift \\ Вилочный погрузчик        645        658       0.19      0.239      0.118     0.0591\n","Bucket loader \\ Ковшовый погрузчик       1091       1166      0.408      0.249      0.273      0.181\n","Mixer (Concrete mixer) \\ Миксер (Автобетономешалка)        493        514      0.707      0.267      0.339      0.233\n","     Tanker \\ Цистерна        382        388      0.342      0.559      0.515      0.331\n"," Bulldozer \\ Бульдозер        412        412      0.462      0.862      0.691      0.539\n","Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/Res/Model/yolov8n_fistech_techniks_v8_50e2\u001b[0m\n"]}]}]}